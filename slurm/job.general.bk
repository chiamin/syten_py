#!/bin/bash
#SBATCH --job-name=test.1DMRG.dense.mea
#SBATCH --partition=TH-WS,TH-CL
#SBATCH --nodes=1
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=10
#SBATCH --mem-per-cpu=3Gb
#SBATCH --threads-per-core=1
#SBATCH --begin=now
#SBATCH --time=48:00:00
#SBATCH --mail-user=chiamin.chung@lmu.de
#SBATCH --no-requeue
#SBATCH --constraint=


INPUT=test.1DMRG.dense.in
OUTPUT=test.1DMRG.dense.mea
EXE="python /project/thcluster/c/ChiaMin.Chung//mypy/sytendmrg/measall.py"

echo dd

slurm_startjob(){
scratch=/data/ChiaMin.Chung
mkdir -p $scratch/$SLURM_JOB_ID/BLKMAT
cp $INPUT $scratch/$SLURM_JOB_ID
cd $scratch/$SLURM_JOB_ID
source /project/thcluster/c/ChiaMin.Chung/syten/envvars.source
echo gg
srun time $EXE $INPUT >> $SLURM_SUBMIT_DIR/$OUTPUT 2>&1
rm -rf $scratch/$SLURM_JOB_ID

echo Job Done
}

#########################################################################

# SLURM environment variables:
# SLURM_JOB_USER             The user who started the job
# SLURM_ARRAY_TASK_ID        Job array ID (index) number.
# SLURM_ARRAY_JOB_ID         Job array’s master job ID number.
# SLURM_JOB_CPUS_PER_NODE    Count of processors available to the job on this node.
# SLURM_JOB_ID                The ID of the job allocation.
# SLURM_JOB_NAME             Name of the job.
# SLURM_JOB_NODELIST         List of nodes allocated to the job.
# SLURM_JOB_NUM_NODES        Total number of nodes in the job’s resource allocation.
# SLURM_JOB_PARTITION        Name of the partition in which the job is running.
# SLURM_NODEID               ID of the nodes allocated.
# SLURMD_NODENAME            Names of all the allocated nodes.
# SLURM_NTASKS               Same as -n, --ntasks
# SLURM_NTASKS_PER_CORE      Number of tasks requested per core. [If specified]
# SLURM_NTASKS_PER_NODE      Number of tasks requested per node. [If specified]
# SLURM_NTASKS_PER_SOCKET    Number of tasks requested per socket. [If specified]
# SLURM_PROCID               The MPI rank (or relative process ID) of the current process.
# SLURM_SUBMIT_DIR           The directory from which sbatch was invoked.
# SLURM_SUBMIT_HOST          The hostname of the computer from which sbatch was invoked.
# SLURM_TASKS_PER_NODE       Number of tasks to be initiated on each node. In the same order as SLURM_JOB_NODELIST.

# Function to echo informational output
slurm_info_out(){
# Informational output
echo "=================================== SLURM JOB ==================================="
date
echo
echo "The job will be started on the following node(s):"
echo $SLURM_JOB_NODELIST
echo
echo "Slurm User:         $SLURM_JOB_USER"
echo "Run Directory:      $(pwd)"
echo "Job ID:             $SLURM_JOB_ID"
echo "Job Name:           $SLURM_JOB_NAME"
echo "Partition:          $SLURM_JOB_PARTITION"
echo "Number of nodes:    $SLURM_JOB_NUM_NODES"
echo "Submitted From:     $SLURM_SUBMIT_HOST:$SLURM_SUBMIT_DIR"
echo "=================================== SLURM JOB ==================================="
echo
echo "--- SLURM job-script output ---"
}

slurm_info_out
slurm_startjob
